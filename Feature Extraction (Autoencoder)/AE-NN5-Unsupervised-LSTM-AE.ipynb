{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63441d01",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-01T18:59:47.960182Z",
     "iopub.status.busy": "2024-01-01T18:59:47.959484Z",
     "iopub.status.idle": "2024-01-01T19:00:04.210120Z",
     "shell.execute_reply": "2024-01-01T19:00:04.208368Z"
    },
    "papermill": {
     "duration": 16.262841,
     "end_time": "2024-01-01T19:00:04.213610",
     "exception": false,
     "start_time": "2024-01-01T18:59:47.950769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (21.3)\r\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons) (3.0.9)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afaec455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:04.229529Z",
     "iopub.status.busy": "2024-01-01T19:00:04.229071Z",
     "iopub.status.idle": "2024-01-01T19:00:19.129180Z",
     "shell.execute_reply": "2024-01-01T19:00:19.127616Z"
    },
    "papermill": {
     "duration": 14.911932,
     "end_time": "2024-01-01T19:00:19.132590",
     "exception": false,
     "start_time": "2024-01-01T19:00:04.220658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tslearn\r\n",
      "  Downloading tslearn-0.6.3-py3-none-any.whl (374 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tslearn) (1.23.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from tslearn) (1.11.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from tslearn) (1.2.2)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from tslearn) (0.57.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from tslearn) (1.3.2)\r\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->tslearn) (0.40.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->tslearn) (3.1.0)\r\n",
      "Installing collected packages: tslearn\r\n",
      "Successfully installed tslearn-0.6.3\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04671141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:19.149143Z",
     "iopub.status.busy": "2024-01-01T19:00:19.148690Z",
     "iopub.status.idle": "2024-01-01T19:00:36.765887Z",
     "shell.execute_reply": "2024-01-01T19:00:36.764389Z"
    },
    "papermill": {
     "duration": 17.62935,
     "end_time": "2024-01-01T19:00:36.769325",
     "exception": false,
     "start_time": "2024-01-01T19:00:19.139975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "import tensorflow_addons as tfa\n",
    "from math import pi, ceil\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5ba5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:36.787021Z",
     "iopub.status.busy": "2024-01-01T19:00:36.785690Z",
     "iopub.status.idle": "2024-01-01T19:00:36.792796Z",
     "shell.execute_reply": "2024-01-01T19:00:36.791248Z"
    },
    "papermill": {
     "duration": 0.019365,
     "end_time": "2024-01-01T19:00:36.796061",
     "exception": false,
     "start_time": "2024-01-01T19:00:36.776696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d505ba7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:36.812593Z",
     "iopub.status.busy": "2024-01-01T19:00:36.812117Z",
     "iopub.status.idle": "2024-01-01T19:00:36.825131Z",
     "shell.execute_reply": "2024-01-01T19:00:36.823498Z"
    },
    "papermill": {
     "duration": 0.024273,
     "end_time": "2024-01-01T19:00:36.827649",
     "exception": false,
     "start_time": "2024-01-01T19:00:36.803376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AEBase(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AEBase, self).__init__(**kwargs)\n",
    "        self.encoder = self.construct_encoder()\n",
    "        self.decoder = self.construct_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(data, reconstruction), axis=(0, 1)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(reconstruction_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3fd8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:36.845125Z",
     "iopub.status.busy": "2024-01-01T19:00:36.844642Z",
     "iopub.status.idle": "2024-01-01T19:00:36.858190Z",
     "shell.execute_reply": "2024-01-01T19:00:36.857212Z"
    },
    "papermill": {
     "duration": 0.025345,
     "end_time": "2024-01-01T19:00:36.860945",
     "exception": false,
     "start_time": "2024-01-01T19:00:36.835600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMAE(AEBase):\n",
    "    def __init__(self, latent_dim=12, encoder_hiddens=[256, 128, 64], decoder_hiddens=[64, 128, 256], series_len=None):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_hiddens = encoder_hiddens\n",
    "        self.decoder_hiddens = decoder_hiddens\n",
    "        self.series_len = series_len\n",
    "        super(LSTMAE, self).__init__()\n",
    "\n",
    "    def construct_encoder(self):\n",
    "        encoder_inputs = keras.Input((None,self.series_len))\n",
    "        #masked_seq = keras.layers.Masking(mask_value=0.0)(encoder_inputs)  # Mask any time step with value 0.0\n",
    "        x = keras.layers.LSTM(self.encoder_hiddens[0], return_sequences=True)(encoder_inputs)\n",
    "        for i in range(1, len(self.encoder_hiddens)-1):\n",
    "            x = keras.layers.LSTM(self.encoder_hiddens[i], return_sequences=True)(x)\n",
    "        x = keras.layers.LSTM(self.encoder_hiddens[-1])(x)\n",
    "        x = layers.Dense(self.latent_dim)(x)\n",
    "        encoder = keras.Model(encoder_inputs,  x, name=\"encoder\")\n",
    "        return encoder\n",
    "\n",
    "    def construct_decoder(self):\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
    "        x = keras.layers.RepeatVector(1)(latent_inputs)\n",
    "        # stacking LSTM layers\n",
    "        for h in self.decoder_hiddens:\n",
    "            x = keras.layers.LSTM(h, return_sequences=True)(x)\n",
    "\n",
    "        decoder_outputs = keras.layers.TimeDistributed(keras.layers.Dense(self.series_len))(x)\n",
    "        decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696bf1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:36.877222Z",
     "iopub.status.busy": "2024-01-01T19:00:36.876729Z",
     "iopub.status.idle": "2024-01-01T19:00:37.013993Z",
     "shell.execute_reply": "2024-01-01T19:00:37.012659Z"
    },
    "papermill": {
     "duration": 0.148496,
     "end_time": "2024-01-01T19:00:37.016538",
     "exception": false,
     "start_time": "2024-01-01T19:00:36.868042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "      <th>785</th>\n",
       "      <th>786</th>\n",
       "      <th>787</th>\n",
       "      <th>788</th>\n",
       "      <th>789</th>\n",
       "      <th>790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.407029</td>\n",
       "      <td>14.725057</td>\n",
       "      <td>20.564059</td>\n",
       "      <td>34.708050</td>\n",
       "      <td>26.629819</td>\n",
       "      <td>16.609977</td>\n",
       "      <td>15.320295</td>\n",
       "      <td>11.607143</td>\n",
       "      <td>19.883787</td>\n",
       "      <td>23.767007</td>\n",
       "      <td>...</td>\n",
       "      <td>50.141723</td>\n",
       "      <td>33.701814</td>\n",
       "      <td>28.656463</td>\n",
       "      <td>26.417234</td>\n",
       "      <td>27.253401</td>\n",
       "      <td>44.373583</td>\n",
       "      <td>65.206916</td>\n",
       "      <td>49.744898</td>\n",
       "      <td>34.481293</td>\n",
       "      <td>32.667234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.550454</td>\n",
       "      <td>13.591270</td>\n",
       "      <td>15.036848</td>\n",
       "      <td>21.570295</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.722222</td>\n",
       "      <td>12.244898</td>\n",
       "      <td>15.504535</td>\n",
       "      <td>18.934240</td>\n",
       "      <td>...</td>\n",
       "      <td>34.665533</td>\n",
       "      <td>13.988095</td>\n",
       "      <td>13.874717</td>\n",
       "      <td>16.326531</td>\n",
       "      <td>17.488662</td>\n",
       "      <td>20.663265</td>\n",
       "      <td>27.097506</td>\n",
       "      <td>32.171202</td>\n",
       "      <td>13.676304</td>\n",
       "      <td>16.369048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.640590</td>\n",
       "      <td>14.399093</td>\n",
       "      <td>24.418934</td>\n",
       "      <td>28.784014</td>\n",
       "      <td>20.620748</td>\n",
       "      <td>13.803855</td>\n",
       "      <td>11.536281</td>\n",
       "      <td>10.742630</td>\n",
       "      <td>14.824263</td>\n",
       "      <td>25.212585</td>\n",
       "      <td>...</td>\n",
       "      <td>38.364512</td>\n",
       "      <td>17.928005</td>\n",
       "      <td>18.041383</td>\n",
       "      <td>16.978458</td>\n",
       "      <td>22.293084</td>\n",
       "      <td>36.522109</td>\n",
       "      <td>42.786281</td>\n",
       "      <td>39.271542</td>\n",
       "      <td>17.446145</td>\n",
       "      <td>17.148526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.180272</td>\n",
       "      <td>8.446712</td>\n",
       "      <td>19.515306</td>\n",
       "      <td>28.883220</td>\n",
       "      <td>19.472789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.355442</td>\n",
       "      <td>10.827664</td>\n",
       "      <td>15.617914</td>\n",
       "      <td>21.159297</td>\n",
       "      <td>...</td>\n",
       "      <td>31.420068</td>\n",
       "      <td>17.276077</td>\n",
       "      <td>15.674603</td>\n",
       "      <td>12.471655</td>\n",
       "      <td>17.928005</td>\n",
       "      <td>25.028345</td>\n",
       "      <td>45.308957</td>\n",
       "      <td>32.242063</td>\n",
       "      <td>15.943878</td>\n",
       "      <td>16.638322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.778912</td>\n",
       "      <td>10.813492</td>\n",
       "      <td>21.612812</td>\n",
       "      <td>38.520408</td>\n",
       "      <td>24.744898</td>\n",
       "      <td>12.329932</td>\n",
       "      <td>12.996032</td>\n",
       "      <td>11.040249</td>\n",
       "      <td>7.950680</td>\n",
       "      <td>19.515306</td>\n",
       "      <td>...</td>\n",
       "      <td>33.758503</td>\n",
       "      <td>18.990930</td>\n",
       "      <td>16.865079</td>\n",
       "      <td>16.000567</td>\n",
       "      <td>15.079365</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>40.646259</td>\n",
       "      <td>33.304989</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>14.101474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  13.407029  14.725057  20.564059  34.708050  26.629819  16.609977   \n",
       "1  11.550454  13.591270  15.036848  21.570295  19.444444   0.000000   \n",
       "2   5.640590  14.399093  24.418934  28.784014  20.620748  13.803855   \n",
       "3  13.180272   8.446712  19.515306  28.883220  19.472789   0.000000   \n",
       "4   9.778912  10.813492  21.612812  38.520408  24.744898  12.329932   \n",
       "\n",
       "         6          7          8          9    ...        781        782  \\\n",
       "0  15.320295  11.607143  19.883787  23.767007  ...  50.141723  33.701814   \n",
       "1   9.722222  12.244898  15.504535  18.934240  ...  34.665533  13.988095   \n",
       "2  11.536281  10.742630  14.824263  25.212585  ...  38.364512  17.928005   \n",
       "3   7.355442  10.827664  15.617914  21.159297  ...  31.420068  17.276077   \n",
       "4  12.996032  11.040249   7.950680  19.515306  ...  33.758503  18.990930   \n",
       "\n",
       "         783        784        785        786        787        788  \\\n",
       "0  28.656463  26.417234  27.253401  44.373583  65.206916  49.744898   \n",
       "1  13.874717  16.326531  17.488662  20.663265  27.097506  32.171202   \n",
       "2  18.041383  16.978458  22.293084  36.522109  42.786281  39.271542   \n",
       "3  15.674603  12.471655  17.928005  25.028345  45.308957  32.242063   \n",
       "4  16.865079  16.000567  15.079365  20.833333  40.646259  33.304989   \n",
       "\n",
       "         789        790  \n",
       "0  34.481293  32.667234  \n",
       "1  13.676304  16.369048  \n",
       "2  17.446145  17.148526  \n",
       "3  15.943878  16.638322  \n",
       "4  16.666667  14.101474  \n",
       "\n",
       "[5 rows x 791 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn5 = pd.read_csv(\"/kaggle/input/nn5-dataset/nn51.csv\", header=None)\n",
    "nn5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfce45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:37.033598Z",
     "iopub.status.busy": "2024-01-01T19:00:37.033090Z",
     "iopub.status.idle": "2024-01-01T19:00:37.044677Z",
     "shell.execute_reply": "2024-01-01T19:00:37.043758Z"
    },
    "papermill": {
     "duration": 0.02308,
     "end_time": "2024-01-01T19:00:37.046984",
     "exception": false,
     "start_time": "2024-01-01T19:00:37.023904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "start_date = datetime(1996, 3, 18)\n",
    "\n",
    "date_range = [start_date + timedelta(days=i) for i in range(nn5.shape[1])]\n",
    "\n",
    "# Convert the date range to days of the week\n",
    "days_of_week = [date.strftime('%A') for date in date_range]\n",
    "nn5.columns = days_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0ee953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:00:37.066109Z",
     "iopub.status.busy": "2024-01-01T19:00:37.065606Z",
     "iopub.status.idle": "2024-01-01T19:02:59.476075Z",
     "shell.execute_reply": "2024-01-01T19:02:59.474629Z"
    },
    "papermill": {
     "duration": 142.431088,
     "end_time": "2024-01-01T19:02:59.485971",
     "exception": false,
     "start_time": "2024-01-01T19:00:37.054883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "106    None\n",
       "107    None\n",
       "108    None\n",
       "109    None\n",
       "110    None\n",
       "Length: 111, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with columns as days of the week\n",
    "\n",
    "# Function to replace zeros with the median of non-zero values for each day of the week\n",
    "def replace_zeros_with_median(series):\n",
    "    # Iterate over unique days of the week\n",
    "    for day in nn5.columns:\n",
    "        # Extract non-zero values for the specific day\n",
    "        non_zero_values = series[series.index == day].replace(0, np.nan).dropna()\n",
    "        \n",
    "        # Calculate the median of non-zero values\n",
    "        median_value = non_zero_values.median()\n",
    "        \n",
    "        # Replace zeros with the median for the specific day\n",
    "        series.loc[series.index == day] = series.loc[series.index == day].replace(0, median_value)\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "nn5.apply(replace_zeros_with_median, axis=1)\n",
    "\n",
    "# Now, df has zeros replaced with the median of non-zero values for each day of the week in each series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1a346c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.503664Z",
     "iopub.status.busy": "2024-01-01T19:02:59.503154Z",
     "iopub.status.idle": "2024-01-01T19:02:59.511849Z",
     "shell.execute_reply": "2024-01-01T19:02:59.510638Z"
    },
    "papermill": {
     "duration": 0.020904,
     "end_time": "2024-01-01T19:02:59.514369",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.493465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    ts_train = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        # for normalization of each series\n",
    "        # mean_temp=np.mean(np.array(list(data.iloc[i][6:].dropna())))\n",
    "        # temp = np.array(list(data.iloc[i][6:].dropna())/mean_temp)\n",
    "        # temp = np.array(list(data.iloc[i][6:].dropna()))\n",
    "        # temp=np.log(temp + 1)\n",
    "        temp=np.array(list(data.iloc[i].dropna()))\n",
    "        temp=temp.reshape(1,len(temp),1)\n",
    "        temp2 = TimeSeriesScalerMeanVariance().fit_transform(temp)\n",
    "        # temp = TimeSeriesScalerMeanVariance().fit_transform(np.array(list(m3.iloc[0][6:].dropna())).reshape(-1,1))\n",
    "\n",
    "        ts_train.append(temp2.reshape(-1,1))\n",
    "\n",
    "    return ts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a795a3ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.532370Z",
     "iopub.status.busy": "2024-01-01T19:02:59.531460Z",
     "iopub.status.idle": "2024-01-01T19:02:59.709116Z",
     "shell.execute_reply": "2024-01-01T19:02:59.707593Z"
    },
    "papermill": {
     "duration": 0.190037,
     "end_time": "2024-01-01T19:02:59.712111",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.522074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_nn5 = preprocessing(nn5)\n",
    "dataset_nn5 = np.array(dataset_nn5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea48b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.730298Z",
     "iopub.status.busy": "2024-01-01T19:02:59.729816Z",
     "iopub.status.idle": "2024-01-01T19:02:59.735958Z",
     "shell.execute_reply": "2024-01-01T19:02:59.734656Z"
    },
    "papermill": {
     "duration": 0.018568,
     "end_time": "2024-01-01T19:02:59.738725",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.720157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length_nn5 = max(len(seq) for seq in dataset_nn5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c7d71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.757437Z",
     "iopub.status.busy": "2024-01-01T19:02:59.756998Z",
     "iopub.status.idle": "2024-01-01T19:02:59.762673Z",
     "shell.execute_reply": "2024-01-01T19:02:59.761301Z"
    },
    "papermill": {
     "duration": 0.01783,
     "end_time": "2024-01-01T19:02:59.764980",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.747150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reshaped_array_nn5 = dataset_nn5.reshape(dataset_nn5.shape[0], 1, dataset_nn5.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf99b483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.783039Z",
     "iopub.status.busy": "2024-01-01T19:02:59.782626Z",
     "iopub.status.idle": "2024-01-01T19:02:59.788140Z",
     "shell.execute_reply": "2024-01-01T19:02:59.787016Z"
    },
    "papermill": {
     "duration": 0.017722,
     "end_time": "2024-01-01T19:02:59.790843",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.773121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 1, 791)\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_array_nn5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d590d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.809843Z",
     "iopub.status.busy": "2024-01-01T19:02:59.809395Z",
     "iopub.status.idle": "2024-01-01T19:02:59.814094Z",
     "shell.execute_reply": "2024-01-01T19:02:59.812976Z"
    },
    "papermill": {
     "duration": 0.017752,
     "end_time": "2024-01-01T19:02:59.817019",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.799267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = [8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4a9bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:02:59.835486Z",
     "iopub.status.busy": "2024-01-01T19:02:59.834855Z",
     "iopub.status.idle": "2024-01-01T19:14:07.562604Z",
     "shell.execute_reply": "2024-01-01T19:14:07.561649Z"
    },
    "papermill": {
     "duration": 667.777212,
     "end_time": "2024-01-01T19:14:07.602401",
     "exception": false,
     "start_time": "2024-01-01T19:02:59.825189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Checking the dimension:  8\n",
      "****************************************************\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 189ms/step - loss: 9.8366 - reconstruction_loss: 9.1645\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 9.3552 - reconstruction_loss: 8.4935\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 6.1955 - reconstruction_loss: 5.2640\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.0336 - reconstruction_loss: 3.9101\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.8146 - reconstruction_loss: 3.7294\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 4.0663 - reconstruction_loss: 3.6720\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.9076 - reconstruction_loss: 3.6780\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7225 - reconstruction_loss: 3.6399\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.9981 - reconstruction_loss: 3.6345\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 4.0021 - reconstruction_loss: 3.6296\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.9734 - reconstruction_loss: 3.6058\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.9382 - reconstruction_loss: 3.5698\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.7902 - reconstruction_loss: 3.5710\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6484 - reconstruction_loss: 3.5675\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.6500 - reconstruction_loss: 3.5616\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.7487 - reconstruction_loss: 3.5616\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.6293 - reconstruction_loss: 3.5612\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.8080 - reconstruction_loss: 3.5599\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.6578 - reconstruction_loss: 3.5577\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.7774 - reconstruction_loss: 3.5554\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8942 - reconstruction_loss: 3.5562\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.8826 - reconstruction_loss: 3.5573\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7254 - reconstruction_loss: 3.5539\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7959 - reconstruction_loss: 3.5558\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.7028 - reconstruction_loss: 3.5541\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.8901 - reconstruction_loss: 3.5526\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.7615 - reconstruction_loss: 3.5518\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7611 - reconstruction_loss: 3.5522\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.7535 - reconstruction_loss: 3.5492\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6554 - reconstruction_loss: 3.5494\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 4.0409 - reconstruction_loss: 3.5465\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.5460 - reconstruction_loss: 3.5480\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.5793 - reconstruction_loss: 3.5473\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 4.0423 - reconstruction_loss: 3.5503\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.7077 - reconstruction_loss: 3.5434\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.4607 - reconstruction_loss: 3.5465\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7808 - reconstruction_loss: 3.5455\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8110 - reconstruction_loss: 3.5455\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7449 - reconstruction_loss: 3.5417\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6377 - reconstruction_loss: 3.5446\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.7842 - reconstruction_loss: 3.5401\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7606 - reconstruction_loss: 3.5423\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7620 - reconstruction_loss: 3.5436\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7877 - reconstruction_loss: 3.5404\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.7724 - reconstruction_loss: 3.5414\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.6162 - reconstruction_loss: 3.5382\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.6644 - reconstruction_loss: 3.5430\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.6610 - reconstruction_loss: 3.5372\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7742 - reconstruction_loss: 3.5388\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 4.0366 - reconstruction_loss: 3.5377\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.9259 - reconstruction_loss: 3.5370\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.9312 - reconstruction_loss: 3.5335\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.8626 - reconstruction_loss: 3.5332\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 3.6157 - reconstruction_loss: 3.5330\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.6714 - reconstruction_loss: 3.5306\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.7029 - reconstruction_loss: 3.5318\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6919 - reconstruction_loss: 3.5304\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.8654 - reconstruction_loss: 3.5310\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.7907 - reconstruction_loss: 3.5293\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.5384 - reconstruction_loss: 3.5313\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 3.6965 - reconstruction_loss: 3.5281\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 3.9021 - reconstruction_loss: 3.5238\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7106 - reconstruction_loss: 3.5199\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 4.0849 - reconstruction_loss: 3.5181\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.8368 - reconstruction_loss: 3.5143\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8627 - reconstruction_loss: 3.5118\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.9341 - reconstruction_loss: 3.5100\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8524 - reconstruction_loss: 3.5015\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.8026 - reconstruction_loss: 3.4920\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.8002 - reconstruction_loss: 3.4804\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.5408 - reconstruction_loss: 3.4597\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.5883 - reconstruction_loss: 3.4443\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.5943 - reconstruction_loss: 3.4376\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 3.5210 - reconstruction_loss: 3.4151\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6765 - reconstruction_loss: 3.4169\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7208 - reconstruction_loss: 3.3948\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.5139 - reconstruction_loss: 3.3755\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.5578 - reconstruction_loss: 3.3564\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.5050 - reconstruction_loss: 3.3418\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.5409 - reconstruction_loss: 3.3328\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.5786 - reconstruction_loss: 3.3078\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.5511 - reconstruction_loss: 3.2894\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.4617 - reconstruction_loss: 3.2744\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.5416 - reconstruction_loss: 3.2693\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.4672 - reconstruction_loss: 3.2636\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.4594 - reconstruction_loss: 3.2321\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.3274 - reconstruction_loss: 3.2163\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.5185 - reconstruction_loss: 3.2052\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.4272 - reconstruction_loss: 3.1946\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.4066 - reconstruction_loss: 3.1968\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.3833 - reconstruction_loss: 3.1814\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.3138 - reconstruction_loss: 3.1720\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.4257 - reconstruction_loss: 3.1650\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.4137 - reconstruction_loss: 3.1539\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.2935 - reconstruction_loss: 3.1389\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.2696 - reconstruction_loss: 3.1338\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.3204 - reconstruction_loss: 3.1305\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.2741 - reconstruction_loss: 3.1054\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.3137 - reconstruction_loss: 3.0877\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.3087 - reconstruction_loss: 3.0409\n",
      "****************************************************\n",
      "Checking the dimension:  16\n",
      "****************************************************\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 9.8362 - reconstruction_loss: 9.1641\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 9.2981 - reconstruction_loss: 8.3507\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 5.7850 - reconstruction_loss: 4.9269\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 4.1451 - reconstruction_loss: 3.8723\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.9646 - reconstruction_loss: 3.7225\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 4.0580 - reconstruction_loss: 3.6771\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.9772 - reconstruction_loss: 3.6497\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 4.1459 - reconstruction_loss: 3.6432\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 4.1237 - reconstruction_loss: 3.6357\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7816 - reconstruction_loss: 3.6243\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 4.0120 - reconstruction_loss: 3.6078\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7284 - reconstruction_loss: 3.5965\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7757 - reconstruction_loss: 3.5788\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.8779 - reconstruction_loss: 3.5681\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6421 - reconstruction_loss: 3.5680\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 4.0194 - reconstruction_loss: 3.5670\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.8952 - reconstruction_loss: 3.5605\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.8248 - reconstruction_loss: 3.5619\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.9544 - reconstruction_loss: 3.5588\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.6111 - reconstruction_loss: 3.5593\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 4.0091 - reconstruction_loss: 3.5582\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7580 - reconstruction_loss: 3.5539\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.9318 - reconstruction_loss: 3.5523\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8721 - reconstruction_loss: 3.5530\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.5191 - reconstruction_loss: 3.5505\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.6330 - reconstruction_loss: 3.5510\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.9633 - reconstruction_loss: 3.5492\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6464 - reconstruction_loss: 3.5551\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.9137 - reconstruction_loss: 3.5490\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.9090 - reconstruction_loss: 3.5506\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.7317 - reconstruction_loss: 3.5463\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.8961 - reconstruction_loss: 3.5465\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7965 - reconstruction_loss: 3.5472\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6562 - reconstruction_loss: 3.5452\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.8885 - reconstruction_loss: 3.5485\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.7657 - reconstruction_loss: 3.5442\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.6833 - reconstruction_loss: 3.5458\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.8947 - reconstruction_loss: 3.5433\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.9500 - reconstruction_loss: 3.5426\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.5924 - reconstruction_loss: 3.5413\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.6805 - reconstruction_loss: 3.5421\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.8944 - reconstruction_loss: 3.5416\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8654 - reconstruction_loss: 3.5420\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8556 - reconstruction_loss: 3.5390\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.5925 - reconstruction_loss: 3.5417\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7127 - reconstruction_loss: 3.5388\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 3.8915 - reconstruction_loss: 3.5393\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.6871 - reconstruction_loss: 3.5365\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7807 - reconstruction_loss: 3.5356\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.9055 - reconstruction_loss: 3.5364\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.8672 - reconstruction_loss: 3.5344\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8812 - reconstruction_loss: 3.5350\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8010 - reconstruction_loss: 3.5324\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.7499 - reconstruction_loss: 3.5316\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7388 - reconstruction_loss: 3.5296\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 4.0155 - reconstruction_loss: 3.5293\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6395 - reconstruction_loss: 3.5290\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8452 - reconstruction_loss: 3.5300\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7545 - reconstruction_loss: 3.5271\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.8637 - reconstruction_loss: 3.5251\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 3.8068 - reconstruction_loss: 3.5266\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 3.6277 - reconstruction_loss: 3.5196\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.6532 - reconstruction_loss: 3.5190\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6787 - reconstruction_loss: 3.5157\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.7516 - reconstruction_loss: 3.5156\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6384 - reconstruction_loss: 3.5146\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.5901 - reconstruction_loss: 3.5094\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.7993 - reconstruction_loss: 3.5013\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6973 - reconstruction_loss: 3.4916\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.6673 - reconstruction_loss: 3.4847\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.7621 - reconstruction_loss: 3.4705\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6550 - reconstruction_loss: 3.4593\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8035 - reconstruction_loss: 3.4527\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.7548 - reconstruction_loss: 3.4418\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.6454 - reconstruction_loss: 3.4303\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 3.7005 - reconstruction_loss: 3.4188\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8087 - reconstruction_loss: 3.4106\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.4281 - reconstruction_loss: 3.3998\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.5641 - reconstruction_loss: 3.3970\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.6285 - reconstruction_loss: 3.3904\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.7232 - reconstruction_loss: 3.3755\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.4849 - reconstruction_loss: 3.3596\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.7400 - reconstruction_loss: 3.3413\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.4119 - reconstruction_loss: 3.3183\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.4736 - reconstruction_loss: 3.2890\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.4010 - reconstruction_loss: 3.2572\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.2957 - reconstruction_loss: 3.2167\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.3581 - reconstruction_loss: 3.1729\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 196ms/step - loss: 3.4735 - reconstruction_loss: 3.1204\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 198ms/step - loss: 3.2185 - reconstruction_loss: 3.0819\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 2s 198ms/step - loss: 3.3901 - reconstruction_loss: 3.0630\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 2s 197ms/step - loss: 3.2043 - reconstruction_loss: 3.0635\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 2s 197ms/step - loss: 3.2330 - reconstruction_loss: 3.0419\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 3.3262 - reconstruction_loss: 3.0526\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.3398 - reconstruction_loss: 3.0333\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 3.4211 - reconstruction_loss: 3.0733\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 3.3072 - reconstruction_loss: 3.0497\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.1005 - reconstruction_loss: 3.0309\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.1794 - reconstruction_loss: 3.0295\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.1441 - reconstruction_loss: 2.9935\n",
      "****************************************************\n",
      "Checking the dimension:  32\n",
      "****************************************************\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 9.8353 - reconstruction_loss: 9.1622\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 9.1365 - reconstruction_loss: 8.0637\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 5.2910 - reconstruction_loss: 4.5037\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 4.2143 - reconstruction_loss: 3.7978\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.8660 - reconstruction_loss: 3.7282\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8268 - reconstruction_loss: 3.6808\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 174ms/step - loss: 3.8283 - reconstruction_loss: 3.6747\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.8253 - reconstruction_loss: 3.6531\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8475 - reconstruction_loss: 3.6469\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.7413 - reconstruction_loss: 3.6399\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 4.2259 - reconstruction_loss: 3.6398\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.9705 - reconstruction_loss: 3.6308\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.6717 - reconstruction_loss: 3.6038\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.9339 - reconstruction_loss: 3.5698\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8354 - reconstruction_loss: 3.5690\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.8486 - reconstruction_loss: 3.5657\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.8967 - reconstruction_loss: 3.5632\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.7423 - reconstruction_loss: 3.5619\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.7214 - reconstruction_loss: 3.5577\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7952 - reconstruction_loss: 3.5587\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.7636 - reconstruction_loss: 3.5555\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.6795 - reconstruction_loss: 3.5580\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.6818 - reconstruction_loss: 3.5601\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.6645 - reconstruction_loss: 3.5580\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.7103 - reconstruction_loss: 3.5580\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.8457 - reconstruction_loss: 3.5539\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 4.0618 - reconstruction_loss: 3.5514\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.8427 - reconstruction_loss: 3.5498\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.6254 - reconstruction_loss: 3.5564\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.6720 - reconstruction_loss: 3.5470\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.8083 - reconstruction_loss: 3.5500\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.6172 - reconstruction_loss: 3.5479\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 3.7782 - reconstruction_loss: 3.5491\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6867 - reconstruction_loss: 3.5457\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.7593 - reconstruction_loss: 3.5450\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.9709 - reconstruction_loss: 3.5445\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.6702 - reconstruction_loss: 3.5502\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.9034 - reconstruction_loss: 3.5435\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 3.9374 - reconstruction_loss: 3.5427\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.9417 - reconstruction_loss: 3.5434\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.7073 - reconstruction_loss: 3.5426\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8925 - reconstruction_loss: 3.5398\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7321 - reconstruction_loss: 3.5403\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.6621 - reconstruction_loss: 3.5375\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.7590 - reconstruction_loss: 3.5367\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.8478 - reconstruction_loss: 3.5386\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6655 - reconstruction_loss: 3.5374\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.7264 - reconstruction_loss: 3.5363\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.5401 - reconstruction_loss: 3.5352\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.5574 - reconstruction_loss: 3.5331\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6365 - reconstruction_loss: 3.5324\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.8006 - reconstruction_loss: 3.5311\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.5038 - reconstruction_loss: 3.5332\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.9049 - reconstruction_loss: 3.5306\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.8687 - reconstruction_loss: 3.5243\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 3.9431 - reconstruction_loss: 3.5270\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.9333 - reconstruction_loss: 3.5215\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.6388 - reconstruction_loss: 3.5186\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.5997 - reconstruction_loss: 3.5176\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.5786 - reconstruction_loss: 3.5145\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.7360 - reconstruction_loss: 3.5104\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 3.7907 - reconstruction_loss: 3.5037\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.7164 - reconstruction_loss: 3.4986\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.7027 - reconstruction_loss: 3.4920\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.8472 - reconstruction_loss: 3.4835\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 4.0568 - reconstruction_loss: 3.4737\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.5892 - reconstruction_loss: 3.4632\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.6400 - reconstruction_loss: 3.4539\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.7524 - reconstruction_loss: 3.4479\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 3.7438 - reconstruction_loss: 3.4346\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.6313 - reconstruction_loss: 3.4319\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.6578 - reconstruction_loss: 3.4264\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.5389 - reconstruction_loss: 3.4110\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.5641 - reconstruction_loss: 3.4034\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.8229 - reconstruction_loss: 3.3983\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.8076 - reconstruction_loss: 3.3959\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.7430 - reconstruction_loss: 3.3962\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.6406 - reconstruction_loss: 3.3852\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.4698 - reconstruction_loss: 3.3510\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.6459 - reconstruction_loss: 3.3166\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 3.5000 - reconstruction_loss: 3.2839\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.4861 - reconstruction_loss: 3.2412\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 3.3950 - reconstruction_loss: 3.1851\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.1682 - reconstruction_loss: 3.1467\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.3997 - reconstruction_loss: 3.1018\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.1418 - reconstruction_loss: 3.0672\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.1572 - reconstruction_loss: 3.0597\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 3.3117 - reconstruction_loss: 3.0699\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 3.2531 - reconstruction_loss: 3.0578\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.3266 - reconstruction_loss: 3.0507\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.3542 - reconstruction_loss: 3.0107\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 3.0989 - reconstruction_loss: 2.9861\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.3118 - reconstruction_loss: 2.9678\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 3.0862 - reconstruction_loss: 2.9406\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 3.2388 - reconstruction_loss: 2.9066\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 3.1015 - reconstruction_loss: 2.8710\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.1037 - reconstruction_loss: 2.8539\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 3.0530 - reconstruction_loss: 2.8335\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 2.9684 - reconstruction_loss: 2.8280\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 3.0774 - reconstruction_loss: 2.8404\n"
     ]
    }
   ],
   "source": [
    "for item in dim:\n",
    "    print(\"****************************************************\")\n",
    "    print(\"Checking the dimension: \", item)\n",
    "    print(\"****************************************************\")\n",
    "    ae_nn5=LSTMAE(latent_dim=item, series_len=max_seq_length_nn5)\n",
    "    ae_nn5.compile(optimizer=keras.optimizers.Adam(),loss=\"mse\")\n",
    "    ae_nn5.fit(reshaped_array_nn5, epochs=100, batch_size=10)\n",
    "    Features_nn5 = ae_nn5.encoder(reshaped_array_nn5)\n",
    "    path = \"Features_nn5_LSTM_\"+str(item)+\".csv\"\n",
    "    np.savetxt(path, Features_nn5, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebee3a",
   "metadata": {
    "papermill": {
     "duration": 0.393518,
     "end_time": "2024-01-01T19:14:08.387514",
     "exception": false,
     "start_time": "2024-01-01T19:14:07.993996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3743351,
     "sourceId": 6479400,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3792584,
     "sourceId": 6564428,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3863893,
     "sourceId": 6704564,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 868.474468,
   "end_time": "2024-01-01T19:14:12.136015",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-01T18:59:43.661547",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
